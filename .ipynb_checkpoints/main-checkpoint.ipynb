{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46ca6379e40a43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T05:07:23.390562Z",
     "start_time": "2024-11-14T05:06:36.869950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.6 MB 1.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.6 MB 1.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.6 MB 1.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.6 MB 1.0 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 1.0 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/11.6 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.6 MB 1.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.6 MB 1.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.9/11.6 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.7/11.6 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.7/11.6 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.9/11.6 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.2/11.6 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.5/11.6 MB 1.0 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.2/11.6 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.5/11.6 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.6 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.0/11.6 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.0/11.6 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.3/11.6 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.1/11.6 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.1/11.6 MB 1.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.3/11.6 MB 1.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.6/11.6 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.9/11.6 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.1/11.6 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 1.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.9/11.6 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.2/11.6 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.4/11.6 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.7/11.6 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.7/11.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.5/11.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.7/11.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 1.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/12.9 MB 1.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/12.9 MB 1.0 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/12.9 MB 1.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 1.0 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 953.2 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 953.2 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 949.8 kB/s eta 0:00:12\n",
      "   ------ --------------------------------- 2.1/12.9 MB 932.4 kB/s eta 0:00:12\n",
      "   ------ --------------------------------- 2.1/12.9 MB 932.4 kB/s eta 0:00:12\n",
      "   ------- -------------------------------- 2.4/12.9 MB 883.0 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.6/12.9 MB 898.8 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.6/12.9 MB 898.8 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.9/12.9 MB 911.8 kB/s eta 0:00:11\n",
      "   --------- ------------------------------ 3.1/12.9 MB 922.7 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 927.9 kB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 927.9 kB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 3.7/12.9 MB 932.1 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.9/12.9 MB 935.8 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 4.2/12.9 MB 939.1 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 4.5/12.9 MB 945.3 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 4.5/12.9 MB 945.3 kB/s eta 0:00:09\n",
      "   -------------- ------------------------- 4.7/12.9 MB 947.6 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.0/12.9 MB 952.7 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 957.3 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 5.5/12.9 MB 961.5 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 965.3 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.0/12.9 MB 966.3 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.0/12.9 MB 966.3 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 6.3/12.9 MB 969.7 kB/s eta 0:00:07\n",
      "   -------------------- ------------------- 6.6/12.9 MB 970.3 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 6.8/12.9 MB 973.2 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 7.1/12.9 MB 973.7 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 976.3 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 976.3 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 976.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 7.9/12.9 MB 979.0 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 8.1/12.9 MB 981.2 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.4/12.9 MB 983.2 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.4/12.9 MB 983.2 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 8.7/12.9 MB 983.3 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 8.9/12.9 MB 985.2 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 986.9 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 988.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 988.6 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 9.7/12.9 MB 988.5 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 10.0/12.9 MB 988.5 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 10.2/12.9 MB 990.0 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 10.5/12.9 MB 991.4 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.7/12.9 MB 991.3 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.7/12.9 MB 991.3 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 992.6 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.3/12.9 MB 993.9 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 995.1 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 995.1 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.8/12.9 MB 985.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.8/12.9 MB 985.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 12.1/12.9 MB 978.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 973.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 973.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 968.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 965.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 963.6 kB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.3 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:23:03.385848Z",
     "start_time": "2024-11-15T16:23:02.447038Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset locally\n",
    "# Replace `file_path` with your local path to BookSum JSON files\n",
    "train_data = pd.read_json('booksum/alignments/book-level-summary-alignments/book_summaries_aligned_train.jsonl', lines=True)\n",
    "val_data = pd.read_json('booksum/alignments/book-level-summary-alignments/book_summaries_aligned_val.jsonl', lines=True)\n",
    "test_data = pd.read_json('booksum/alignments/book-level-summary-alignments/book_summaries_aligned_test.jsonl', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7157e0ba53517608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T05:25:51.875757Z",
     "start_time": "2024-11-14T05:25:38.155445Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (18.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.0-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.17.1-cp310-cp310-win_amd64.whl.metadata (66 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached aiohttp-3.11.0-cp310-cp310-win_amd64.whl (439 kB)\n",
      "Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Using cached yarl-1.17.1-cp310-cp310-win_amd64.whl (89 kB)\n",
      "Installing collected packages: multidict, fsspec, frozenlist, filelock, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.0 aiosignal-1.3.1 async-timeout-5.0.1 datasets-3.1.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.2 multidict-6.1.0 multiprocess-0.70.16 yarl-1.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741aa582cb74ef21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:23:08.476977Z",
     "start_time": "2024-11-15T16:23:07.340843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['bid', 'source', 'title', 'summary_path', 'book_path'],\n",
      "        num_rows: 314\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['bid', 'source', 'title', 'summary_path', 'book_path'],\n",
      "        num_rows: 45\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['bid', 'source', 'title', 'summary_path', 'book_path'],\n",
      "        num_rows: 46\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Convert to DatasetDict format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "booksum_data = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "print(booksum_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8fbc6de2eb68790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T05:44:28.321698Z",
     "start_time": "2024-11-14T05:44:25.119068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ojas\\onedrive\\desktop\\mlr project\\.venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e538e9e42ee888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:23:20.412633Z",
     "start_time": "2024-11-15T16:23:18.565533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1929397f9e4fbaaf7edcf025665a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951a4e0d40b2494aaaf5516628494674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ce7135b4a844648b83ba450e090f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/46 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load BART or T5 tokenizer\n",
    "model_name = 'facebook/bart-large'  # or 't5-large' for T5 model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define preprocessing\n",
    "max_input_length = 1024\n",
    "max_output_length = 150\n",
    "\n",
    "import os\n",
    "\n",
    "def preprocess(batch):\n",
    "    book_path = batch['book_path']\n",
    "    summary_path = batch['summary_path']\n",
    "    \n",
    "    # Check if both files exist\n",
    "    if not os.path.exists(book_path) or not os.path.exists(summary_path):\n",
    "        print(f\"Skipping missing files: {book_path} or {summary_path}\")\n",
    "        return {}  # Return an empty dictionary to skip this batch\n",
    "\n",
    "    # Read the book text and summary\n",
    "    with open(book_path, 'r', encoding='utf-8') as book_file:\n",
    "        book_text = book_file.read()\n",
    "    with open(summary_path, 'r', encoding='utf-8') as summary_file:\n",
    "        summary_text = summary_file.read()\n",
    "\n",
    "    inputs = tokenizer(book_text, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(summary_text, max_length=max_output_length, truncation=True, padding=\"max_length\")\n",
    "    inputs['labels'] = targets['input_ids']\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "# tokenized_data = booksum_data.map(preprocess, batched=False)\n",
    "valid_data = booksum_data.filter(lambda example: os.path.exists(example['book_path']) and os.path.exists(example['summary_path']))\n",
    "tokenized_data = valid_data.map(preprocess, batched=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bce95c-c69e-48e1-969d-46a2589fbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b3e68054231ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSeq2SeqLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(model_name)\n\u001b[0;32m      5\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      6\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     predict_with_generate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\MLR project\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1651\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1651\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\MLR project\\.venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1639\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1637\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForSeq2SeqLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    eval_dataset=tokenized_data['validation'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c18a8021604b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Your sample chapter or paragraph text here.\"\n",
    "inputs = tokenizer(sample_text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
    "summary_ids = model.generate(inputs['input_ids'], max_length=max_output_length, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(\"Generated Summary:\", tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
